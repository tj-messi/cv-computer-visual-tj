#image classification

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1728381803488.png)

#图像分类
动机。在本节中，我们将介绍图像分类问题，该问题的任务是从一组固定的类别中为输入图像分配一个标签。这是计算机视觉中的核心问题之一，尽管它很简单，但实际应用范围很广。此外，正如我们将在本课程后面看到的那样，许多其他看似不同的计算机视觉任务（例如对象检测、分割）可以简化为图像分类。

示例。例如，在下图中，图像分类模型采用单个图像，并将概率分配给 4 个标签 {cat， dog， hat， mug}。如图所示，请记住，对于计算机来说，图像表示为一个大型 3 维数字数组。在此示例中，cat 图像宽 248 像素，高 400 像素，具有三个颜色通道 Red、Green、Blue（或简称 RGB）。因此，该图像由 248 x 400 x 3 个数字组成，或总共 297,600 个数字。每个数字都是一个整数，范围从 0（黑色）到 255（白色）。我们的任务是将这四分之一的百万个数字变成一个标签，比如 “cat”。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241008180401.png)

图像分类中的任务是预测给定图像的单个标签（或如此处所示的标签分布，以表明我们的置信度）。图像是从 0 到 255 的 3 维整数数组，大小为 Width x Height x 3。3 表示三个颜色通道 Red、Green、Blue

**挑战**。由于识别视觉概念（例如猫）的任务对人类来说相对简单，因此值得从计算机视觉算法的角度考虑所涉及的挑战。正如我们在下面提供（详尽的）挑战列表时，请记住图像的原始表示为亮度值的 3-D 数组：

**视点变化**。对象的单个实例可以以多种方式相对于相机进行定向。
**比例变化**。视觉类的大小通常会发生变化（在现实世界中的大小，而不仅仅是它们在图像中的范围）。
变形。许多感兴趣的对象不是刚体，可以以极端方式变形。
遮挡。感兴趣的对象可以被遮挡。有时，只有对象的一小部分 （少至几个像素） 可见。
**照明条件**。照明的影响在像素级别上是巨大的。
**背景杂乱**。感兴趣的对象可能会融入其环境，使其难以识别。
**类内差异**。感兴趣的类通常相对较宽，例如 chair。这些对象有许多不同类型的对象，每种对象都有自己的外观。
一个好的图像分类模型必须对所有这些变化的叉积不变，同时保持对类间变化的敏感性。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241008180807.png)

**数据驱动的方法**。我们如何编写一种可以将图像分类为不同类别的算法？与编写算法（例如，对数字列表进行排序）不同，如何编写用于识别图像中猫的算法并不明显。因此，我们将采用的方法与你对孩子采取的方法没有什么不同，而不是试图直接在代码中指定每个感兴趣的类别是什么样子的：我们将为计算机提供每个类的许多示例，然后开发学习算法来查看这些示例并了解每个类的视觉外观。这种方法被称为数据驱动方法，因为它依赖于首先积累标记图像的训练数据集。以下是此类数据集的示例：

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241008180837.png)

图像分类管道。我们已经看到，图像分类中的任务是获取代表单个图像的像素数组并为其分配标签。我们的完整管道可以具体化如下：

输入：我们的输入由一组 N 张图像组成，每张图像都标有 K 个不同类别的一个。我们将这些数据称为训练集。
学习：我们的任务是使用训练集来了解每个类是什么样子的。我们将此步骤称为训练分类器或学习模型。
评估：最后，我们通过要求分类器预测一组以前从未见过的新图像的标签来评估分类器的质量。然后，我们将这些图像的真实标签与分类器预测的标签进行比较。直觉上，我们希望很多预测与真实答案（我们称之为基本事实）相匹配。

##最近邻分类器

作为我们的第一种方法，我们将开发我们所谓的最近邻分类器。这个分类器与卷积神经网络无关，在实践中很少使用，但它可以让我们了解图像分类问题的基本方法。

图像分类数据集示例：CIFAR-10。一种流行的玩具图像分类数据集是 CIFAR-10 数据集。该数据集由 60,000 张高和宽 32 像素的微小图像组成。每张图像都标有 10 个类之一（例如“飞机、汽车、鸟等”）。这 60000 张图像被划分为一个包含 50000 张图像的训练集和一个包含 10000 张图像的测试集。在下图中，您可以看到 10 个类中每个类的 10 个随机示例图像：

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241008180932.png)

假设现在我们获得了 50,000 张图像的 CIFAR-10 训练集（每个标签 5,000 张图像），我们希望标记剩余的 10,000 张图像。最近邻分类器将获取测试图像，将其与每个训练图像进行比较，并预测最近的训练图像的标签。在上图和右侧，您可以看到 10 个示例测试图像的此类过程的示例结果。请注意，在 10 个示例中，只有大约 3 个检索了同一类的图像，而在其他 7 个示例中，情况并非如此。例如，在第 8 行中，离马头最近的训练图像是一辆红色汽车，这可能是由于强烈的黑色背景。因此，在这种情况下，这张马的图像会被错误地标记为汽车。

您可能已经注意到，我们没有具体说明我们如何比较两张图像的细节，在本例中，这两张图片只是两个 32 x 32 x 3 的块。最简单的方法之一就是逐个像素地比较图片，然后把所有的差异相加。换句话说，给定两个图像并将它们表示为向量I1,I2
，比较它们的合理选择可能是 L1 距离：

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1728382246828.png)

换句话说，我们会像以前一样计算像素级差异，但这次我们把它们都平方，把它们相加，最后得到平方根。在 numpy 中，使用上面的代码我们只需要替换一行代码。计算距离的线
	
	distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1))

请注意，我包含了上面的调用，但在实际的最近邻应用程序中，我们可以省略平方根运算，因为平方根是一个单调函数。也就是说，它缩放距离的绝对大小，但保留排序，因此有或没有距离的最近邻域是相同的。如果你在这个距离的 CIFAR-10 上运行最近邻分类器，你将获得 35.4% 的准确率（略低于我们的 L1 距离结果）。np.sqrt

L1 与 L2。考虑这两个指标之间的差异是很有趣的。特别是，当涉及到两个向量之间的差异时，L2 距离比 L1 距离要宽容得多。也就是说，L2 距离更喜欢许多中等的不一致，而不是一个大的不一致。L1 和 L2 距离（或等效于一对图像之间差值的 L1/L2 范数）是 p 范数最常用的特殊情况。

##k-最近邻分类器

你可能已经注意到，当我们想进行预测时，只使用最近图像的标签是很奇怪的。事实上，几乎总是通过使用所谓的 k 最近邻分类器可以做得更好。这个想法非常简单：我们不是在训练集中找到最接近的单个图像，而是找到前 k 个最近的图像，并让它们对测试图像的标签进行投票。特别是，当 k = 1 时，我们恢复 Nearest Neighbor 分类器。直观地说，较高的 k 值具有平滑效果，使分类器更能抵抗异常值：

在实践中，您几乎总是希望使用 k-最近邻。但是你应该使用 k 的什么值呢？接下来我们来看这个问题。

###超参数优化的验证集

k 最近邻分类器需要 k 的设置。但是什么数字最有效呢？此外，我们还看到我们可以使用许多不同的距离函数：L1 范数、L2 范数，还有许多其他我们甚至没有考虑的选择（例如点积）。这些选择称为超参数，它们经常出现在许多从数据中学习的机器学习算法的设计中。通常不清楚应该选择什么值/设置。

您可能会建议我们应该尝试许多不同的值，看看哪种值最有效。这是一个好主意，这确实是我们将要做的，但这必须非常谨慎地进行。特别是，我们不能将测试集用于调整超参数。每当设计机器学习算法时，都应该将测试集视为非常宝贵的资源，理想情况下，在最后的一次之前，它不应该被触及。否则，非常真实的危险是，您可能会调整超参数以在测试集上正常工作，但如果您要部署模型，则可能会看到性能显著降低。在实践中，我们会说你过度拟合到测试集。另一种看待它的方法是，如果您在测试集上调整超参数，则实际上是在将测试集用作训练集，因此，您在测试集上实现的性能对于部署模型时可能实际观察到的情况来说过于乐观。但是，如果你只在最后使用一次测试集，它仍然是测量分类器泛化的良好代理（我们将在本课程后面看到更多关于泛化的讨论）

**在测试集上仅评估一次，即最后。**

幸运的是，有一种正确的方法来调整超参数，它根本不触及测试集。这个想法是将我们的训练集一分为二：一个稍小的训练集，以及我们所说的验证集。以 CIFAR-10 为例，例如，我们可以使用 49000 张训练图像进行训练，并留出 1000 张用于验证。此验证集本质上用作模拟测试集来调整超参数

**将训练集拆分为训练集和验证集。使用验证集优化所有超参数。最后，在测试集上运行一次并报告性能。**

**交叉验证**。 在训练数据（以及验证数据）的大小可能很小的情况下，人们有时会使用一种更复杂的技术进行超参数优化，称为交叉验证。使用前面的示例，我们的想法是，通过迭代不同的验证集并平均这些验证集的性能，您可以更好、更少地估计 k 的某个值的工作情况，而不是武断地选择前 1000 个数据点作为验证集和 REST 训练集。例如，在 5 折交叉验证中，我们会将训练数据分成 5 个相等的折叠，其中 4 个用于训练，1 个用于验证。然后，我们将迭代哪个折叠是验证折叠，评估性能，最后平均不同折叠的性能。

在实践中。在实践中，人们更愿意避免交叉验证，而倾向于使用单个验证拆分，因为交叉验证的计算成本可能很高。人们倾向于使用的 splits 是 50%-90% 的训练数据用于训练，其余部分用于验证。但是，这取决于多个因素：例如，如果超参数的数量很大，您可能更喜欢使用更大的验证拆分。如果验证集中的示例数量很少（可能只有几百个左右），则使用交叉验证会更安全。您在实践中可以看到的典型折叠数是 3 倍、5 倍或 10 倍交叉验证。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241008182634.png)