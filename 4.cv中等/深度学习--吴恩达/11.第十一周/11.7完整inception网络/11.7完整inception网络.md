#11.7完整inception网络

Inception模块会将之前层的激活或者输出作为它的输入

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241004003936.png)

之后分几条路去进行卷积：

1：1x1卷积

2: 1x1卷积 再 3x3卷积

3：1x1卷积 再 5x5卷积

4：最大池 再 1x1卷积

最后，将这些方块全都连接起来。在这过程中，把得到的各个层的通道都加起来，最后得到一个28×28×256的输出。通道连接实际就是之前视频中看到过的，把所有方块连接在一起的操作。这就是一个Inception模块，而Inception网络所做的就是将这些模块都组合到一起

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241004004055.png)

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241004004131.png)

这是一张取自Szegety et al的论文中关于Inception网络的图片，你会发现图中有许多重复的模块，可能整张图看上去很复杂，但如果你只截取其中一个环节（编号1），就会发现这是在前一页ppt中所见的Inception模块。

我们深入看看里边的一些细节，这是另一个Inception模块（编号2），这也是一个Inception模块（编号3）。这里有一些额外的最大池化层（编号6）来修改高和宽的维度。这是另外一个Inception模块（编号4），这是另外一个最大池化层（编号7），它改变了高和宽。而这里又是另一个Inception模块（编号5）。

所以Inception网络只是很多这些你学过的模块在不同的位置重复组成的网络，所以如果你理解了之前所学的Inception模块，你就也能理解Inception网络

最后总结一下，如果你理解了Inception模块，你就能理解Inception网络，无非是很多个Inception模块一环接一环，最后组成了网络。自从Inception模块诞生以来，经过研究者们的不断发展，衍生了许多新的版本。所以在你们看一些比较新的Inception算法的论文时，会发现人们使用这些新版本的算法效果也一样很好，比如Inception V2、V3以及V4，还有一个版本引入了跳跃连接的方法，有时也会有特别好的效果。但所有的这些变体都建立在同一种基础的思想上，在之前的视频中你就已经学到过，就是把许多Inception模块通过某种方式连接到一起。通过这个视频，我想你应该能去阅读和理解这些Inception的论文，甚至是一些新版本的论文。

直到现在，你已经了解了许多专用的神经网络结构。在下节视频中，我将会告诉你们如何真正去使用这些算法来构建自己的计算机视觉系统


