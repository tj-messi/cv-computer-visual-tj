#10.10卷积神经网络示例

###例子
假设，有一张大小为32×32×3的输入图片，这是一张RGB模式的图片，你想做手写体数字识别。32×32×3的RGB图片中含有某个数字，比如7，你想识别它是从0-9这10个数字中的哪一个，我们构建一个神经网络来实现这个功能

输入是32×32×3的矩阵，假设第一层使用过滤器大小为5×5，步幅是1，padding是0，过滤器个数为6，那么输出为28×28×6。将这层标记为CONV1，它用了6个过滤器，增加了偏差，应用了非线性函数，可能是ReLU非线性函数，最后输出CONV1的结果

然后构建一个池化层，这里我选择用最大池化，参数 f = 2 ， s = 2  ，因为padding为0，我就不写出来了。现在开始构建池化层，最大池化使用的过滤器为2×2，步幅为2，表示层的高度和宽度会减少一半。因此，28×28变成了14×14，通道数量保持不变，所以最终输出为14×14×6，将该输出标记为POOL1

这里，我们把CONV1和POOL1共同作为一个卷积，并标记为Layer1。虽然你在阅读网络文章或研究报告时，你可能会看到卷积层和池化层各为一层的情况，这只是两种不同的标记术语。一般我在统计网络层数时，只计算具有权重的层，也就是把CONV1和POOL1作为Layer1。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241002175643.png)

我们再为它构建一个卷积层，过滤器大小为5×5，步幅为1，这次我们用10个过滤器，最后输出一个10×10×10的矩阵，标记为CONV2。

然后做最大池化，超参数 f = 2 ， s = 2 。你大概可以猜出结果， f = 2 ， s = 2  ，高度和宽度会减半，最后输出为5×5×10，标记为POOL2，这就是神经网络的第二个卷积层，即Layer2。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241002180101.png)

5×5×16矩阵包含400个元素，现在将POOL2平整化为一个大小为400的一维向量。我们可以把平整化结果想象成这样的一个神经元集合，然后利用这400个单元构建下一层。下一层含有120个单元，这就是我们第一个全连接层，标记为FC3。这400个单元与120个单元紧密相连，这就是全连接层。它很像我们在第一和第二门课中讲过的单神经网络层，这是一个标准的神经网络。它的权重矩阵为 W [ 3 ] W^{[3]}W 
[3]
  ，维度为120×400。这就是所谓的“全连接”，因为这400个单元与这120个单元的每一项连接，还有一个偏差参数。最后输出120个维度，因为有120个输出。

然后我们对这个120个单元再添加一个全连接层，这层更小，假设它含有84个单元，标记为FC4

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241002180357.png)

最后，用这84个单元填充一个softmax单元。如果我们想通过手写数字识别来识别手写0-9这10个数字，这个softmax就会有10个输出

####参数个数

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241002180454.png)