#10.7单层卷积网络

###单层卷积网络搭建例子

通过两个过滤器卷积处理一个三维图像，并输出两个不同的4×4矩阵。假设使用第一个过滤器进行卷积，得到第一个4×4矩阵。使用第二个过滤器进行卷积得到另外一个4×4矩阵

最终各自形成一个卷积神经网络层，然后增加偏差，它是一个实数，通过Python的广播机制给这16个元素都加上同一偏差。然后应用非线性函数，为了说明，它是一个非线性激活函数ReLU，输出结果是一个4×4矩阵。

对于第二个4×4矩阵，我们加上不同的偏差，它也是一个实数，16个数字都加上同一个实数，然后应用非线性函数，也就是一个非线性激活函数ReLU，最终得到另一个4×4矩阵。然后重复我们之前的步骤，把这两个矩阵堆叠起来，最终得到一个4×4×2的矩阵。我们通过计算，从6×6×3的输入推导出一个4×4×2矩阵，它是卷积神经网络的一层，把它映射到标准神经网络中四个卷积层中的某一层或者一个非卷积神经网络中

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241002171148.png)

###组合单层卷积

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241002171805.png)

这一部分（图中蓝色边框标记的部分）就是应用激活函数ReLU之前的值，它的作用类似于，最后应用非线性函数，得到的这个4×4×2矩阵，成为神经网络的下一层，也就是激活层。

这就是 a [ 0 ] a^{[0]}a 
[0]
  到 a [ 1 ] a^{[1]}a 
[1]
  的演变过程，首先执行线性函数，然后所有元素相乘做卷积，具体做法是运用线性函数再加上偏差，然后应用激活函数ReLU。这样就通过神经网络的一层把一个6×6×3的维度 a [ 0 ] a^{[0]}a 
[0]
  演化为一个4×4×2维度的 a [ 1 ] a^{[1]}a 
[1]
  ，这就是卷积神经网络的一层。

示例中我们有两个过滤器，也就是有两个特征，因此我们才最终得到一个4×4×2的输出。但如果我们用了10个过滤器，而不是2个，我们最后会得到一个4×4×10维度的输出图像，因为我们选取了其中10个特征映射，而不仅仅是2个，将它们堆叠在一起，形成一个4×4×10的输出图像，也就是 a [ 1 ] a^{[1]}a 
[1]
 

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241002171949.png)