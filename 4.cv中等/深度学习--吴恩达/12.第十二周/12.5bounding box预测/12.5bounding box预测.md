#12.5bounding box预测

滑动窗口法的卷积实现，这个算法效率更高，但仍然存在问题，不能输出最精准的边界框。在这个视频中，我们看看如何得到更精准的边界框

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241004122553.png)

在滑动窗口法中，你取这些离散的位置集合，然后在它们上运行分类器，在这种情况下，这些边界框没有一个能完美匹配汽车位置，也许这个框（编号1）是最匹配的了。还有看起来这个真实值，最完美的边界框甚至不是方形，稍微有点长方形（红色方框所示），长宽比有点向水平方向延伸，有没有办法让这个算法输出更精准的边界框呢

##yolo

其中一个能得到更精准边界框的算法是YOLO算法，YOLO(You only look once)意思是你只看一次，这是由Joseph Redmon，Santosh Divvala，Ross Girshick和Ali Farhadi提出的算法。

是这么做的，比如你的输入图像是100×100的，然后在图像上放一个网格。为了介绍起来简单一些，我用3×3网格，实际实现时会用更精细的网格，可能是19×19。基本思路是使用图像分类和定位算法，前几个视频介绍过的，然后将算法应用到9个格子上。（基本思路是，采用图像分类和定位算法，本周第一个视频中介绍过的，逐一应用在图像的9个格子中。）更具体一点，你需要这样定义训练标签，所以对于9个格子中的每一个指定一个标签 y ， y 是8维的，和你之前看到的一样

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1728016366142.png)

p 
c
​
  等于0或1取决于这个绿色格子中是否有图像。然后 b x 、 b y 、 b h b_x、b_y、b_hb 
x
​
 、b 
y
​
 、b 
h
​
  和 b w b_wb 
w
​
  作用就是，如果那个格子里有对象，那么就给出边界框坐标。然后 c 1 、 c 2 c_1、c_2c 
1
​
 、c 
2
​
  和 c 3 c_3c 
3
​
  就是你想要识别的三个类别，背景类别不算，所以你尝试在背景类别中识别行人、汽车和摩托车，那么 c 1 、 c 2 c_1、c_2c 
1
​
 、c 
2
​
  和 c 3 c_3c 
3
​
  可以是行人、汽车和摩托车类别。这张图里有9个格子，所以对于每个格子都有这么一个向量

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241004123329.png)

要注意，首先这和图像分类和定位算法非常像，我们在本周第一节课讲过的，就是它显式地输出边界框坐标，所以这能让神经网络输出边界框，可以具有任意宽高比，并且能输出更精确的坐标，不会受到滑动窗口分类器的步长大小限制。其次，这是一个卷积实现，你并没有在3×3网格上跑9次算法，或者，如果你用的是19×19的网格，19平方是361次，所以你不需要让同一个算法跑361次。相反，这是单次卷积实现，但你使用了一个卷积网络，有很多共享计算步骤，在处理这3×3计算中很多计算步骤是共享的，或者你的19×19的网格，所以这个算法效率很高

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1728029924231.png)

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241004161906.png)