#12.5bounding box预测

滑动窗口法的卷积实现，这个算法效率更高，但仍然存在问题，不能输出最精准的边界框。在这个视频中，我们看看如何得到更精准的边界框

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241004122553.png)

在滑动窗口法中，你取这些离散的位置集合，然后在它们上运行分类器，在这种情况下，这些边界框没有一个能完美匹配汽车位置，也许这个框（编号1）是最匹配的了。还有看起来这个真实值，最完美的边界框甚至不是方形，稍微有点长方形（红色方框所示），长宽比有点向水平方向延伸，有没有办法让这个算法输出更精准的边界框呢

##yolo

其中一个能得到更精准边界框的算法是YOLO算法，YOLO(You only look once)意思是你只看一次，这是由Joseph Redmon，Santosh Divvala，Ross Girshick和Ali Farhadi提出的算法。

是这么做的，比如你的输入图像是100×100的，然后在图像上放一个网格。为了介绍起来简单一些，我用3×3网格，实际实现时会用更精细的网格，可能是19×19。基本思路是使用图像分类和定位算法，前几个视频介绍过的，然后将算法应用到9个格子上。（基本思路是，采用图像分类和定位算法，本周第一个视频中介绍过的，逐一应用在图像的9个格子中。）更具体一点，你需要这样定义训练标签，所以对于9个格子中的每一个指定一个标签 y ， y 是8维的，和你之前看到的一样

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1728016366142.png)

p 
c
​
  等于0或1取决于这个绿色格子中是否有图像。然后 b x 、 b y 、 b h b_x、b_y、b_hb 
x
​
 、b 
y
​
 、b 
h
​
  和 b w b_wb 
w
​
  作用就是，如果那个格子里有对象，那么就给出边界框坐标。然后 c 1 、 c 2 c_1、c_2c 
1
​
 、c 
2
​
  和 c 3 c_3c 
3
​
  就是你想要识别的三个类别，背景类别不算，所以你尝试在背景类别中识别行人、汽车和摩托车，那么 c 1 、 c 2 c_1、c_2c 
1
​
 、c 
2
​
  和 c 3 c_3c 
3
​
  可以是行人、汽车和摩托车类别。这张图里有9个格子，所以对于每个格子都有这么一个向量

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241004123329.png)

要注意，首先这和图像分类和定位算法非常像，我们在本周第一节课讲过的，就是它显式地输出边界框坐标，所以这能让神经网络输出边界框，可以具有任意宽高比，并且能输出更精确的坐标，不会受到滑动窗口分类器的步长大小限制。其次，这是一个卷积实现，你并没有在3×3网格上跑9次算法，或者，如果你用的是19×19的网格，19平方是361次，所以你不需要让同一个算法跑361次。相反，这是单次卷积实现，但你使用了一个卷积网络，有很多共享计算步骤，在处理这3×3计算中很多计算步骤是共享的，或者你的19×19的网格，所以这个算法效率很高

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1728029924231.png)

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241004161906.png)

在YOLO算法中，对于这个方框（编号1所示），我们约定左上这个点是( 0 , 0 0,00,0 )，然后右下这个点是( 1 , 1 1,11,1 ),要指定橙色中点的位置， b x b_xb 
x
​
  大概是0.4，因为它的位置大概是水平长度的0.4，然后 b y b_yb 
y
​
  大概是0.3，然后边界框的高度用格子总体宽度的比例表示，所以这个红框的宽度可能是蓝线（编号2所示的蓝线）的90%，所以 b h b_hb 
h
​
  是0.9，它的高度也许是格子总体高度的一半，这样的话 b w b_wb 
w
​
  就是0.5。换句话说， b x 、 b y 、 b h b_x、b_y、b_hb 
x
​
 、b 
y
​
 、b 
h
​
  和 b w b_wb 
w
​
  单位是相对于格子尺寸的比例，所以 b x b_xb 
x
​
  和 b y b_yb 
y
​
  必须在0和1之间，因为从定义上看，橙色点位于对象分配到格子的范围内，如果它不在0和1之间，如果它在方块外，那么这个对象就应该分配到另一个格子上。这个值（ b h b_hb 
h
​
  和 b w b_wb 
w
​
  ）可能会大于1，特别是如果有一辆汽车的边界框是这样的（编号3所示），那么边界框的宽度和高度有可能大于1。

指定边界框的方式有很多，但这种约定是比较合理的，如果你去读YOLO的研究论文，YOLO的研究工作有其他参数化的方式，可能效果会更好，我这里就只给出了一个合理的约定，用起来应该没问题。不过还有其他更复杂的参数化方式，涉及到sigmoid函数，确保这个值（ b x b_xb 
x
​
  和 b y b_yb 
y
​
  ）介于0和1之间，然后使用指数参数化来确保这些（ b h b_hb 
h
​
  和 b w b_wb 
w
​
  ）都是非负数，因为0.9和0.5，这个必须大于等于0。还有其他更高级的参数化方式，可能效果要更好一点，但我这里讲的办法应该是管用的。

这就是YOLO算法，你只看一次算法，在接下来的几个视频中，我会告诉你一些其他的思路可以让这个算法做的更好。在此期间，如果你感兴趣，也可以看看YOLO的论文，在前几张幻灯片底部引用的YOLO论文。

Redmon, Joseph, et al. “You Only Look Once: Unified, Real-Time Object Detection.” (2015):779-788.

不过看这些论文之前，先给你们提个醒，YOLO论文是相对难度较高的论文之一，我记得我第一次读这篇论文的时候，我真的很难搞清楚到底是怎么实现的，我最后问了一些我认识的研究员，看看他们能不能给我讲清楚，即使是他们，也很难理解这篇论文的一些细节。所以如果你看论文的时候，发现看不懂，这是没问题的，我希望这种场合出现的概率要更低才好，但实际上，即使是资深研究员也有读不懂研究论文的时候，必须去读源代码，或者联系作者之类的才能弄清楚这些算法的细节。但你们不要被我吓到，你们可以自己看看这些论文，如果你们感兴趣的话，但这篇论文相对较难。现在你们了解了YOLO算法的基础，我们继续讨论别的让这个算法效果更好的研究

