#5.10梯度消失梯度爆炸


假设你在训练一个很深的神经网络，当你设置W内的具体数值，经过多次迭代之后，output y^hat 会呈指数上升或者指数递减。

就会变得很小或者很大

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1726814670149.png)

此时使用很小的学习率（步长）就会使得学习很慢很慢

