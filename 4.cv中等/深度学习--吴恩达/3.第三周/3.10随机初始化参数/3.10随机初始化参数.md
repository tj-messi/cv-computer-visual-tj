#3.10随机初始化参数

对于logistic回归，可以初始化参数全为0。但是对于神经网络来说，如果全把参数初始化，再使用梯度下降法，那会完全无效。

##例子

有两个输入特征，输入层n^[0] == 2 然后有两个隐藏单元，n^[1] == 2 还有和隐藏层相关的 W ^ [1] ，是 2*2的矩阵，如果4个元素全部初始化为0 ， 然后 b ^ [1] 是 1*2 全部初始化为 0 

这样子在反向传递的时候 dz^[1]_1 和 dz^[1]_2 是一致的。计算的时候就输出的是一样的激活函数（无论经过了多少次迭代），不只是两个神经元的时候，多个也是一样的。所以没有意义

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1725282819708.png)

##解决

可以w^[1]=np.random.randn((2,2))*0.01

来进行随机初始化，*0.01是因为合适tanh和sigmoid函数的输入

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1725283384702.png)
