#seq2seq

##简介

在⾃然语⾔处理的很多应⽤中，输⼊和输出都可以是不定⻓序列。以机器翻译为例，输⼊可以是⼀段不定⻓的英语⽂本序列，输出可以是⼀段不定⻓的法语⽂本序列，例如：

英语输⼊：“They”、“are”、“watching”、“.”

法语输出：“Ils”、“regardent”、“.”

当输⼊和输出都是不定⻓序列时，我们可以使⽤编码器—解码器（encoder-decoder）或者seq2seq模型。序列到序列模型，简称seq2seq模型。这两个模型本质上都⽤到了**两个循环神经⽹络**，分别叫做编码器和解码器。编码器⽤来分析输⼊序列，解码器⽤来⽣成输出序列。两个循环神经网络是共同训练的。

下图描述了使⽤编码器—解码器将上述英语句⼦翻译成法语句⼦的⼀种⽅法。在训练数据集中，我们可以在每个句⼦后附上特殊符号“<eos>”（end of sequence）以表⽰序列的终⽌。编码器每个时间步的输⼊依次为英语句⼦中的单词、标点和特殊符号“<eos>”。下图中使⽤了编码器在 最终时间步的隐藏状态作为输⼊句⼦的表征或编码信息。解码器在各个时间步中使⽤输⼊句⼦的 编码信息和上个时间步的输出以及隐藏状态作为输⼊。我们希望解码器在各个时间步能正确依次 输出翻译后的法语单词、标点和特殊符号“<eos>”。需要注意的是，解码器在最初时间步的输⼊ ⽤到了⼀个表⽰序列开始的特殊符号**“”（beginning of sequence）**。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108211731.png)

##编码器

编码器的作⽤是把⼀个不定⻓的输⼊序列变换成⼀个定⻓的背景变量 c，并在该背景变量中编码输⼊序列信息。常⽤的编码器是循环神经⽹络。

让我们考虑批量⼤小为1的时序数据样本。假设输⼊序列是 x1, . . . , xT，例如 xi 是输⼊句⼦中的第 i 个词。在时间步 t，循环神经⽹络将输⼊ xt 的特征向量 xt 和上个时间步的隐藏状态

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108211943.png)

变换为当前时间步的隐藏状态ht。我们可以⽤函数 f 表达循环神经⽹络隐藏层的变换：

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108212012.png)

例如，当选择 q(h1*, . . . ,* hT ) = hT 时，背景变量是输⼊序列最终时间步的隐藏状态hT。

以上描述的编码器是⼀个单向的循环神经⽹络，每个时间步的隐藏状态只取决于该时间步及之前的输⼊⼦序列。我们也可以使⽤双向循环神经⽹络构造编码器。在这种情况下，编码器每个时间步的隐藏状态同时取决于该时间步之前和之后的⼦序列（包括当前时间步的输⼊），并编码了整个序列的信息。

##解码器

例如，当选择 q(h1*, . . . ,* hT ) = hT 时，背景变量是输⼊序列最终时间步的隐藏状态hT。

以上描述的编码器是⼀个单向的循环神经⽹络，每个时间步的隐藏状态只取决于该时间步及之前的输⼊⼦序列。我们也可以使⽤双向循环神经⽹络构造编码器。在这种情况下，编码器每个时间步的隐藏状态同时取决于该时间步之前和之后的⼦序列（包括当前时间步的输⼊），并编码了整个序列的信息。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108212212.png)

和背景变量 c，即：

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108212246.png)

为此，我们可以使⽤另⼀个循环神经⽹络作为解码器。在输出序列的时间步 t′，解码器将上⼀时间步的输出

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108212306.png)

以及背景变量 c 作为输⼊，并将它们与上⼀时间步的隐藏状态

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108212321.png)

变换为当前时间步的隐藏状态st′。因此，我们可以⽤函数 g 表达解码器隐藏层的变换：

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108212336.png)