#CNN

##简介

**卷积神经网络**（Convolutional Neural Networks, CNN）是一类包含卷积计算且具有深度结构的前馈神经网络（Feedforward Neural Networks），是深度学习（deep learning）的代表算法之一。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108143612.png)

上图中CNN要做的事情是：给定一张图片，是车还是马未知，是什么车也未知，现在需要模型判断这张图片里具体是一个什么东西，总之输出一个结果：如果是车 那是什么车。

最左边是数据输入层(input layer)，对数据做一些处理，比如去均值（把输入数据各个维度都中心化为0，避免数据过多偏差，影响训练效果）、归一化（把所有的数据都归一到同样的范围）、PCA/白化等等。CNN只对训练集做“去均值”这一步。

CONV：**卷积计算层**(conv layer)，线性乘积求和。

RELU：**激励层**(activation layer)，下文有提到：ReLU是激活函数的一种。

POOL：**池化层**(pooling layer)，简言之，即取区域平均或最大。

FC：**全连接层**(FC layer)。

这几个部分中，卷积计算层是CNN的核心。

##输入层

在做输入的时候，需要把图片处理成同样大小的图片才能够进行处理。

常见的处理数据的方式有：

去均值(常用)

AlexNet：训练集中100万张图片，对每个像素点求均值，得到均值图像，当训练时用原图减去均值图像。

VGG：对所有输入在三个颜色通道R/G/B上取均值，只会得到3个值，当训练时减去对应的颜色通道均值。(此种方法效率高)

**TIPS:**在训练集和测试集上减去训练集的均值。

归一化

幅度归一化到同样的范围。

PCA/白化(很少用)

用PCA降维
白化是对数据每个特征轴上的幅度归一化。

##卷积层

对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐个元素相乘再求和）的操作就是所谓的『卷积』操作，也是卷积神经网络的名字来源。

滤波器filter是什么呢！请看下图。图中左边部分是原始输入数据，图中中间部分是滤波器filter，图中右边是输出的新的二维数据。

不同的滤波器filter会得到不同的输出数据，比如颜色深浅、轮廓。**相当于提取图像的不同特征，模型就能够学习到多种特征。**用不同的滤波器filter，提取想要的关于图像的特定信息：颜色深浅或轮廓。如下图所示。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108144116.png)

在CNN中，滤波器filter（带着一组固定权重的神经元）对局部输入数据进行卷积计算。每计算完一个数据窗口内的局部数据后，数据窗口不断平移滑动，直到计算完所有数据。这个过程中，有这么几个参数：

**深度depth**：神经元个数，决定输出的depth厚度。同时代表滤波器个数。

**步长stride**：决定滑动多少步可以到边缘。

**填充值zero-padding**：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总长能被步长整除。

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108144357.png)

参数共享机制

假设每个神经元连接数据窗的权重是固定对的。固定每个神经元连接权重，可以看做模板，每个神经元只关注一个特性(模板)，这使得需要估算的权重个数减少：一层中从1亿到3.5万。

一组固定的权重和不同窗口内数据做内积：卷积

作用在于捕捉某一种模式，具体表现为很大的值。

卷积操作的本质特性包括稀疏交互和参数共享。

##激励层

把卷积层输出结果做非线性映射。

激活函数有：

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/20241108144618.png)

**sigmoid**：在两端斜率接近于0，梯度消失。

**ReLu**：修正线性单元，有可能出现斜率为0，但概率很小，因为mini-batch是一批样本损失求导之和。

tips：

CNN慎用sigmoid！慎用sigmoid！慎用sigmoid！
首先试RELU，因为快，但要小心点。
如果RELU失效，请用 Leaky ReLU或者Maxout。
某些情况下tanh倒是有不错的结果，但是很少

##池化层

也叫下采样层，就算通过了卷积层，纬度还是很高 ，需要进行池化层操作。

夹在连续的卷积层中间。
压缩数据和参数的量，降低维度。
减小过拟合。
具有特征不变性。

方式有：**Max pooling、average pooling**

**Max pooling**

取出每个部分的最大值作为输出，例如上图左上角的4个黄色方块取最大值为3作为输出，以此类推。

**average pooling**

每个部分进行计算得到平均值作为输出，例如上图左上角的4个黄色方块取得平均值2作为输出，以此类推。