# Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation

psp框架：生成一系列style向量，然后输入到预训练的StyleGAN中，形成扩展的W+。

**StyleGAN** 实现人脸图像的可控可编辑。

编码器基于特征金字塔网络，每一个style从不同的金字塔层级中抽取，然后直接插入到预训练的StyleGAN中。这个过程称为pixel2stylepixel。

创新点

(i)一个能直接编码真实图像到隐空间的的StyleGAN编码器；

(ii)一个通用的解决image2image的端到端框架。

**GAN反转**

**潜在空间操纵**

**图像到图像的翻译任务**

![image-20230627160032728](C:\Users\31486\AppData\Roaming\Typora\typora-user-images\image-20230627160032728.png)

pSp框架是基于StyleGAN的生成器和其提出的 W+ 空间，这个 W+ 空间styleGAN2中的一个小改进，相当于把随机生成的 z向量通过几个随即层映射到了一个可控的 W+ 空间。

但是这里做得不是GAN，而是图像风格迁移之类的任务，所以需要先将图片映射到latent space里，这个latent space是一个解耦合的空间，也就是将原本可能特征之间有相关性的矩阵映射为矩阵之间的特征无相关性。最简单的方法就是将图片通过一个encoder(ResNet,VGG等等)直接embedding到W+空间维度（512），但是这种方法效果并不够好。无法很好encoding原图像的细节。

在StyleGAN里，其使用了一个金字塔型的encoding，从粗到细粒度，框架图如图1.按照这种思想，pSp同样提出了一个三层的金字塔特征框架，先通过ResNet提取三层vector，每一层层过一个map2style的全连接层之后再过一个全连接层A输入到styleGAN生成器的各个style中去，每一个style都有一个 w 。所以最后pSp生成的图像是由styleGAN预训练好的生成器得到的图片。
