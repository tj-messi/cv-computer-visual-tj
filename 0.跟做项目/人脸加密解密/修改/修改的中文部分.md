我们首次将人脸面部感知-记忆-联想重识别的机制应用于海量监控视频处理，对该机制进行抽象建模，提出了用于对监控视频中的人脸进行加密/解密的算法框架，包括三个步骤：人脸识别与人脸加密，高维语义特征存储和联想匹配，以及高分辨率解密还原人脸。该加解密算法流程应用于监控处理，有望减少数据存储量，降低通信成本，减少隐私泄露可能，提高监控数据检索效率，为智慧城市下大规模摄像头协同使用带来新突破。

受到人类联想记忆机制的启发，将仿人联想记忆机制的自主人脸降级加解密算法融入人工智能人脸识别算法，在数据集上初步验证了对视频中显示身份的人脸区域进行选择性加密和解密的算法。基于YOLOv5-face检测人脸，并在人脸检测框内添加密钥（马赛克），将添加密钥的人脸存储到本地库。用带有年龄信息（50岁的人脸）的图片作为输入与带有密钥的人脸进行特征相似匹配，特征相似的可以对本地库的加密图片进行解密，使用GAN网络（styleGAN）生成清晰的人脸，将加密的人脸恢复到清晰的人脸。

我们证明，选择余弦相似度（取最高相似度）作为匹配标准，并选择一些高维特征作为匹配基础的特征匹配效果会更好，这也反向验证了人脸联想重识别过程中高维抽象语义特征的重要性。



**主要贡献：**

1) 首次将人脸面部感知-记忆-关联再识别机制应用于海量监控视频处理，对该机制进行抽象建模，提出了基于类人感知-关联记忆的人脸加解密算法流程。该加密解密算法过程应用于监控处理，有望减少数据存储量，降低通信成本，减少隐私泄露的可能性，提高监控数据检索效率，为智慧城市下大规模摄像头的协同使用带来新的突破。
2）将仿照人类联想记忆机制的自主人脸降级加解密算法集成到人工智能人脸识别算法中，并在数据集上初步验证了对视频中显示身份的人脸区域进行选择性加解密的算法。
3）我们对匹配方式和损失函数的选取进行分析，证明使用余弦相似度（取最高相似度）作为匹配准则，选择一些高维特征作为匹配基础，特征匹配效果会更好，这也反向验证了高维抽象语义特征在人脸关联再识别过程中的重要性。



第二节介绍了该方法的相关工作，包括基于dl的故障诊断和基于MLP的视觉模型。第三节对人类识别人脸，记忆及联想重识别的过程进行建模抽象，提出了类人认知机制的人脸加解密算法流程，这是本文所提出的加解密算法的核心。在第四节中，详细介绍了所提出的加解密算法在数据集上的初步验证情况。第五节介绍了结论和未来的工作。



基于密码学的人脸隐私保护方案对视频中显示身份的人脸区域进行选择性加密，在未来有合法需求时可解密恢复原始视频。如何将仿人联想记忆机制的自主人脸降级加解密算法融入人工智能人脸识别算法，是一个亟待突破的方向。

借鉴类人认知机制，我们提出







本文针对海量视频数据灾难和个人隐私问题，提出了一种基于高低维信息关联认知机制的视频抽象加解密算法。在存储视频时，采用基于 YOLOv5 的人脸识别和人脸加密算法对视频进行加密，同时提取人脸的高低维语义信息形成特征密钥，并与视频中的人脸建立索引关联，存储在视频对应的密钥池中。解密时，利用从指定新人脸中提取的特征在密钥池中进行搜索，并利用 GAN 模型将匹配的人脸还原为清晰的人脸。我们在一个自建数据集上初步验证了这种视频加解密算法的可行性。我们的研究对于如何在隐私保护和机器视觉研究之间取得平衡具有重要意义。未来，该算法有望在隐私保护与大数据存储、人脸再识别等领域发挥重要作用。









 directly encoding a given sketch image into the desired, transformed latent code, pairing a pSp encoder with a pre-trained StyleGAN allows one to generate realistic images

The pixel2style2pixel (pSp) architecture. Based on an FPN-based architecture, our encoder extracts the intermediate style representation of a given real image at three different spatial scales, corresponding to the coarse, medium, and fine style groups of StyleGAN.

pixel2style2pixel (pSp) 架构。基于基于 FPN 的架构，我们的编码器以三种不同的空间尺度提取给定真实图像的中间风格表示，分别对应于 StyleGAN 的粗、中、细风格组。 请注意，在训练过程中，预训练的 StyleGAN 生成器保持不变，只有编码器使用我们策划的损失函数集进行训练。



While we explored various architectures, our final encoder is based on a Feature Pyramid Network (FPN) with a ResNet-based backbone. This hierarchical architecture is motivated by the hierarchical nature of StyleGAN in which different input layers correspond to different levels of details. Specifically, given an input image, we begin by extracting feature maps at three different spatial scales. Given these feature maps, we then introduce simple intermediate convolutional networks named map2style blocks to extract the 18 different style vectors corresponding to the W+\mathcal{W}+
W+
 style representation of the input image. Finally, by feeding this learned intermediate representation to StyleGAN we obtain the reconstructed image. We provide an overview of this architecture in Figure 3.

虽然我们探索了各种架构，但最终的编码器还是基于以 ResNet 为骨干的特征金字塔网络 (FPN)。这种分层架构的灵感来源于 StyleGAN 的分层性质，其中不同的输入层对应不同的细节层次。具体来说，给定一幅输入图像，我们首先提取三种不同空间尺度的特征图。给定这些特征图后，我们引入名为 map2style 块的简单中间卷积网络，以提取对应于 W+\mathcal{W}+ 的 18 种不同风格向量。
W+
 输入图像的风格表示。最后，通过将学习到的中间表示反馈给 StyleGAN，我们就得到了重建图像。图 3 是该架构的概览。







从解决各种图像到图像转换任务的pixel2style2pixel (pSp) framework中收到启发，我们使用psp encoder，直接编码给定的图像到所需的latent code，来提取高维抽象语义特征B

在实际应用中，可在上述计算公式后引入自定义的数学转换运算，生成定制化的转换密钥，这样保证各监控云平台密钥的个性化与安全性。





**数据集部分**

实验中所使用的数据集为generated_yellow-stylegan2，该数据集是基于StyleGAN2制作的人脸生成器纯随机(无筛选)生成的黄种人脸数据集，包含一万张不同性别、不同年龄、不同头部姿势变化的黄种人脸图像。在训练和加密人脸过程中，我们将该数据集作为输入，并使用基于YOLO5-face 的高斯加密方法获得与原始图像配对的高斯加密数据集。在需要解密时，我们使用Wondershare 打造的人工智能云平台AIlab中的**Age Filter**对47张来自generated_yellow-stylegan2数据集的图片做老化处理，大部分图片都采用了该平台中默认的老化到50岁的设置，可以获得较好的老化处理效果，确保脸部的特征变化仍然是相对可辨识的，获得更加自然和合理的结果。且不至于图像过于老化，出现过于极端和不现实的结果，失去可辨识性，保证了生成结果的逼真度和可信度。将老化后的图像作为新输入的图像，老化处理用于模拟真实解密还原情况下经历一段时间后原人脸的正常生理变化，从而更加真实地模拟整个监控视频人脸加解密流程。



实验数据集可在该链接(https://github.com/a312863063/generators-with-stylegan2)处访问和获得。







解密时，输入一张新捕获的人脸。新捕获的人脸 P2 使用相同的编码模型进行编码以提取特征，提取的特征按一定的维度与人脸特征密钥池中的特征进行匹配。根据人脸特征的相似性判断其是否在数据集中出现过，可在实验中多次训练定义可确定人脸出现过的最低相似度阈值。如果未出现，则拒绝解密。如果出现过，则确认其身份 ID，并将其与之前存储的特征密钥一起输入到 styleGAN 的生成器中，用指定 ID 的马赛克对人脸进行解密，然后输出解密后还原的人脸。styleGAN 使用无监督图像超分辨率方法将低分辨率图像转化为高质量、高分辨率图像，从而再现图像的细节特征，如肤色、眼睛、嘴唇等。





在解密阶段，我们使用相同的编码模型对新捕获的人脸 P2 进行编码，以提取其独特的特征。这些提取到的特征将按照一定的维度或匹配标准与存储在人脸特征密钥池中的密钥进行匹配。通过测量人脸特征的相似性，我们可以判断该人脸是否在云端人脸密钥池中出现过。在实验中，我们可以多次训练并定义一个可接受的最低相似度阈值，以确定人脸是否被确认为已出现过。

如果人脸特征是全新的，即在密钥池中无法找到匹配的密钥，系统将拒绝解密。这个安全措施确保我们只解密已经注册的人脸，从而保护数据的隐私。

如果人脸特征在密钥池中可以找到匹配的密钥，我们将确认其身份 ID，且密钥附带有时空索引，将提供人脸区域在监控视频中的信息。由于本地存储的是人脸区域高斯模糊后的视频，该视频没有办法直接解密人脸区域的，所以必须通过GAN来生成解密之后的人脸，从而才能够进行人脸的恢复.将该密钥输入到 styleGAN 的生成器中，这个生成器将使用指定的密钥 生成一个还原后的人脸图像，然后将其应用于监控视频，实现解密。进一步，styleGAN 利用无监督图像超分辨率方法，将低分辨率的图像转化为高质量、高分辨率图像。这个过程重塑了图像的细节特征，例如肤色、眼睛、嘴唇等，使解密后的人脸恢复到原始的外貌。

通过以上流程，我们实现了一种安全的解密方法，只允许已注册人脸的解密，同时保护个人隐私和图像质量。



1) 拿着这个密钥去跟云端密钥池中的密钥进行匹配，找到了匹配的密钥
2) 这个密钥附带有时空索引等，所以只要知道是哪个密钥就知道要解密的部分是哪里，然后将这个密钥放到了styleGAN的生成器中生成解密以后的人脸，并用这个人脸将视频对应区域进行还原，就可以得到解密之后的视频了。
3) 本地存储的是高斯模糊以后的视频，这个视频是没有办法直接解密的，所以必须通过GAN来生成解密之后的人脸，从而才能够进行人脸的恢复.
4) （这个地方稍微改了一下，感觉本地不做复杂度很高的训练过程也可以，可以把原始视频中的人脸上传到云端以后再做提取密钥的过程）



人脸加密和解密的效果如图5所示。其中原始图片用“Original”表示，它呈现了未经处理的人脸P1。经过加密处理后的图片被标记为 "Blurred"，在这个版本中人脸已被高斯模糊化，难以辨识人脸的身份信息，保护了个人隐私。另一方面，经过老化处理以后的图片称之为"Aged"，这代表了新捕获的人脸P2。将P2经过编码模型提取特征，与云端密钥池匹配后，在匹配的人脸特征密钥引导下，实现了对加密人脸图像的解密还原。这个解密过程产生了 "Recovered" 图片，它呈现了恢复到原始状态的人脸。这一过程能够还原之前加密的模糊化图像，使其重新获得清晰、可识别的特征。







在实验中，有 47 张照片经过人脸老化处理，用同一模型提取特征后，取一定的维度与人脸特征密钥库中的特征进行匹配，并计算匹配的准确率。
实验中选择了不同的维度选择和不同的匹配标准，以充分探讨不同匹配方法的影响。维度选择组合包括：从高维度匹配：1, 1-2, 1-3, ... , 1-18；从低维度匹配： 18, 17-18, 16-18, ... 使用的匹配标准是余弦相似度（取最大相似度）和欧拉距离（取最小距离）。不同匹配方法的匹配精度如下表所示。

在实验中，我们对于47张经过人脸老化处理的照片使用了同一模型来提取特征。然后，我们从这些提取的特征中选取了一定的维度，与预先构建的人脸特征密钥库中的特征进行匹配，并计算匹配的准确率。该匹配准确率可以被计算如下:

Accuracy=匹配正确成功还原的人脸数/全部的人脸数(47)

其中TP表示匹配正确成功还原的人脸数，N表示测试集的人脸数，即经过人脸老化处理的新输入图像数47

为了充分研究不同匹配方法的影响，我们在实验中采用了不同的维度选择组合。这些组合涵盖了从高维度到低维度的匹配方式，具体而言，高维度匹配从维度1开始，依次为1-2、1-3，一直到1-18；低维度匹配则从维度18开始，以步长为1递减，依次为17-18、16-18等等。

在匹配过程中，我们采用了余弦相似度和欧拉距离作为匹配标准。对于余弦相似度，我们选择了最大相似度作为匹配结果；而对于欧拉距离，我们选择了最小距离作为匹配结果。不同匹配方法的匹配精度在表一和表二中列出。表一表示了从高维开始匹配，余弦相似度和欧拉距离两种匹配标准的匹配精度。表二表示了从低维开始匹配，两种匹配标准的匹配精度。四种匹配方法对比度见图6.从图中可以看出，随着使用的latent code layers变多，四种方法的匹配精度都基本呈现出增长趋势。但是“Cosine similarity matches from high dimensions”基本都取得最高精度，且最高精度为0.9362。但最高精度并不出现在latent code layers used=18处，这表明可能从高维开始匹配，随着使用的latent code layers层数变多，低维度信息被更多地引入到特征匹配中，反而可能导致匹配效果变差。


这个观察引发了深入的思考，揭示了不同维度的特征提取器在捕捉数据方面的多样性。不同维度的信息可能在关注数据的不同层面和细节方面扮演着重要角色。具体而言，低维度的特征提取器可能更专注于捕捉局部特征，例如数据中的微小变化和细节。相比之下，高维度的特征提取器则更倾向于捕捉全局特征，涉及数据的整体结构和抽象概念。

这种观点在人脸识别领域的应用中尤其显著。人脸辨识任务更加依赖于高维抽象信息，这可能与我们人类的面孔识别过程相呼应。在人类的脑海中，人脸识别不仅涉及到局部特征，如眼睛、嘴巴等，还包括了整体的面部结构和高级语义特征。这种观察实际上为人脸联想重识别提供了有力支持，表明人类在人脸识别中更加关注高维度的语义特征。

在解决匹配问题时，我们需要认识到维度的不同在特征表达中的角色。适当地平衡低维度和高维度信息的引入，以及如何将它们融合，将有助于提升匹配效果。综上所述，这一观察为我们理解特征提取的多样性以及不同维度信息在匹配任务中的作用提供了有益的洞见。



在人脸加解密的领域中，解密还原人脸的保真度和相似度在决定解密结果质量方面扮演着至关重要的角色。为了追求高质量的人脸重建还原，我们采用多种方法来计算人脸还原的相似度。这些方法不仅考虑了图像的像素级保真度，还深入分析了图像中的面部特征和属性，以更准确地评估还原结果与原始参考之间的相似程度，为训练损失函数的选择提供方向和参考。

首先我们引入了像素级L2损失函数，计算公式如下:

其中Pi表示输入的人脸图像，FPPSD(*)表示整个人脸加解密算法框架，FPPSD(*Pi)表示整个经过加解密流程后还原重建的人脸。

利用该损失函数，我们可以测量解密后的面部图像与修复后的面部图像之间的像素级差异，从而为重建过程的保真度提供一个可量化的指标。使用上述损失函数修复 47 幅老化图像的评估结果如图6所示。在四种不同的匹配方法中，利用高维度的余弦相似性匹配产生的损失值最低。这表明，采用这种匹配方法最终能在修复过程中获得最高的面部相似度。此外，值得注意的是，使用相对较少的高维信息已经使损失值显著降低，达到了一个最低的点。然而，像素级L2损失函数可能无法捕捉到一些微妙的面部特征差异，这些特征对于视觉相似度具有重要意义。

为了更全面地衡量人脸还原的相似度，保证还原的人脸图像与原始图像在感知上的相似度，引入Loss Perceptual Image Patch Similarity（LPIPS）损失。具体而言，该损失通过比较原始人脸图像和经过解密重建后的人脸图像在特征表示空间中的距离来评估它们之间的相似性。该损失函数的数学表达式为：

通过使用LPIPS损失函数，我们能够确保还原后的人脸图像在感知上与原始图像保持相似，从而为解密过程的整体质量提供保障。这种方法不仅能够定量地评估图像的感知相似度，还能够优化解密结果，使其更符合人眼对图像质量的感知标准。使用上述损失函数修复 47 幅老化图像的评估结果如图6所示。从图中可以观察到，使用LPIPS损失函数进行修复的过程中，四种不同的匹配方法在随着使用的latent code layers增加时，损失逐渐降低，与图(a)类似。

最后，为了确保加解密过程中的输入和输出都是人脸图像，我们引入了与人脸识别相关的身份损失函数，通过比较输入图像和通过编码网络获得的输出图像在人脸识别方面的相似度来确保图像的身份一致性。

具体而言，身份损失的计算方式如下：

其中R表示预训练好的ArcFace网络，<*>表示计算输出图像和原图像之间的余弦相似度。

评估结果见图6.从图中可以观察到，使用身份损失时，四种不同的匹配方法一样在随着使用的latent code layers增加时，损失逐渐降低。但相比其他两种损失函数收敛速度稍微慢一点。这暗示了引入身份损失会增加模型训练的复杂性，但能够带来更好的保真度和相似度还原结果。



本部分我们详细介绍了我们采用的多种损失函数以及它们的设计原理。我们通过在人脸加解密流程中嵌入这些损失函数，实现了对解密还原人脸质量的全面评估。实验结果表明，上述多种损失函数的组合能够有效地衡量还原结果的保真度和相似度，从而为高质量的人脸重建还原提供了坚实的基础。



我们使用pSp encoder来完成上述数据集的训练提取latent code，该模型在 ResNet 的基础上使用标准特征金字塔来提取特征映射。对于 18 种目标风格，我们分别训练了一个小型映射网，从相应的特征映射中提取所学风格。0-2 种风格由小型特征映射生成，3-6 种风格由中型特征映射生成，7-18 种风格由大型特征映射生成。与类人认知机制中人脑的高维抽象记忆和压缩感知过程相对应，高维特征信息由较小的特征映射生成。我们首先从训练集中提取原始人脸 P1，使用图3的算法流程训练 P1，从低维到高维提取多维人脸特征，并将这些信息整合加密形成密钥，与处理后的人脸身份 ID 绑定，加入人脸密钥池，并存储在 existing_faces.pkl 中。





本文针对海量视频数据灾难和个人隐私问题，提出了一种基于高低维信息关联认知机制的视频抽象加解密算法。在存储视频时，采用基于 **YOLO5-face** 的人脸识别和人脸加密算法对视频进行加密，同时利用**pSp encoder**提取人脸的高低维语义信息形成特征密钥，并与视频中的人脸建立索引关联，存储在视频对应的密钥池中。解密时，利用从指定新人脸中提取的特征在密钥池中进行搜索，并利用 **styleGAN generator**将匹配的人脸还原为清晰的人脸。我们在一个自建数据集上初步验证了这种视频加解密算法的可行性。同时我们对匹配方式和损失函数的选取进行分析，证明使用余弦相似度（取最高相似度）作为匹配准则，选择一些高维特征作为匹配基础，特征匹配效果会更好，这也反向验证了高维抽象语义特征在人脸关联再识别过程中的重要性。我们的研究对于如何在隐私保护和机器视觉研究之间取得平衡具有重要意义。未来，该算法有望在隐私保护与大数据存储、人脸再识别等领域发挥重要作用。
