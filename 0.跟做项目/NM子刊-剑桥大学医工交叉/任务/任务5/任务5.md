# 任务5

把mouse kidney改为human 

## 修改guide fusion中新的dataloader类

路径

	/media/cbtil/T7 Shield/NMI/code/guided_diffusion/img.py


修改dataloader

	class VisiumhdhumanTonsil(Dataset):
	    def __init__(self, data_root, dataset_use,SR_times, status, gene_num, all_gene, gene_order,gene_name_order):
	        '''
	            data_root: 数据根目录路径
	            SR_times: 下采样倍数
	            status: 数据集状态 'Train' 或 'Test'
	            gene_num: 基因数量
	            all_gene: 总基因数（用于reshape）
	            gene_order: 基因顺序索引
	        '''
	
	        if dataset_use == 'Visiumhd_human_Tonsil':
	            sample_name = ['20250220humantonsil']
	        else:
	            raise ValueError('Invalid dataset_use')
	
	        self.selected_patches = []  # 存储符合条件的样本路径
	        self.gene_order = gene_order
	        self.gene_name_order = gene_name_order
	        self.gene_num = gene_num
	        # 根据status筛选符合条件的patch
	
	        if dataset_use == 'Visiumhd_human_Tonsil':
	                # 根据 patch 名称中下划线分割后的第二部分判断 patch 编号
	                
	            for sample_id in sample_name:
	                # 以HR_ST目录为基准获取所有patch列表（假设其他数据目录结构相同）
	                base_path = f"{data_root}{dataset_use}/HR_ST/extract/{sample_id}"
	                print('base_path',base_path)
	                sub_patches = os.listdir(base_path)
	                # 第一步：收集该样本的所有有效行号
	                row_numbers = []
	                for patch_id in sub_patches:
	                    parts = patch_id.split('_')
	                    if len(parts) < 2:
	                        continue  # 跳过非法格式
	                    try:
	                        b = int(parts[1])  # 提取行号
	                        row_numbers.append(b)
	                    except ValueError:
	                        continue  # 跳过无法转换为整数的情况
	                
	                # 第二步：计算分界点（获取独特的行号并排序）
	                unique_rows = sorted(set(row_numbers))
	                total_rows = len(unique_rows)
	                # print(total_rows,total_rows)
	                # 第三步：根据总行数确定训练/测试分界点
	                if total_rows <= 5:
	                    # 如果总行数≤4，最后1行用9于测试
	                    train_max_row = unique_rows[-2] if total_rows > 1 else -1
	                elif total_rows <= 10:
	                    # 如果总行数在5-8之间，最后2行用于测试
	                    train_max_row = unique_rows[-3]
	                else:
	                    # 如果行数更多，大约20%用于测试（向上取整）
	                    test_count = max(int(total_rows * 0.2 + 0.5), 3)  # 至少3行测试
	                    train_max_row = unique_rows[-(test_count + 1)]
	                # print(train_max_row)
	                # 第四步：遍历patch并应用新的划分逻辑
	                for patch_id in sub_patches:
	                    parts = patch_id.split('_')
	                    if len(parts) < 2:
	                        continue  # 跳过非法格式
	                    
	                    try:
	                        b = int(parts[1])  # 提取行号
	                        
	                        # 应用新的动态划分规则
	                        # if status == 'Train' and (train_max_row == -1 or b <= train_max_row):
	                        #     # print('patch_id',patch_id)
	                        #     self.selected_patches.append((sample_id, patch_id))
	                        # elif status == 'Test' and (train_max_row == -1 or b > train_max_row):
	                        #     self.selected_patches.append((sample_id, patch_id))
	                        
	                        # test取全体
	                        if status == 'Train' and (train_max_row == -1 or b <= train_max_row):
	                            # print('patch_id',patch_id)
	                            self.selected_patches.append((sample_id, patch_id))
	                        elif status == 'Test' and (train_max_row == -1 or b > train_max_row):
	                            self.selected_patches.append((sample_id, patch_id))
	
	                    except ValueError:
	                        continue  # 跳过无法转换为整数的情况
	            # 初始化数据容器
	            SR_ST_all, spot_ST_all, WSI_5120_all,WSI_320_all = [], [], [],[]
	            self.gene_scale = []
	
	            # 有序输出
	            if status == 'Test':
	                self.selected_patches.sort(key=lambda x: (int(x[1].split('_')[0]), int(x[1].split('_')[1])))
	        #print('self.selected_patches',self.selected_patches)
	        # print(self.selected_patches)
	        # 统一加载逻辑（确保三个数据部分顺序一致）
	        for sample_id, patch_id in self.selected_patches:
	            # ------------------- 加载HR_ST -------------------
	            hr_st_dir = f"{data_root}{dataset_use}/HR_ST/extract/{sample_id}/{patch_id}/"
	            if SR_times == 10:
	                #print(os.path.join(data_root,dataset_use,'HR_ST/extract/', patch_id, 'HR_ST_256.npz'))
	                SR_ST = sp_sparse.load_npz(os.path.join(data_root,dataset_use,'HR_ST/extract/',sample_id, patch_id, 'HR_ST_256.npz')).toarray().reshape(256, 256, 200)
	            elif SR_times == 5:
	                SR_ST = sp_sparse.load_npz(os.path.join(data_root,dataset_use,'HR_ST/extract/',sample_id, patch_id, 'HR_ST_128.npz')).toarray().reshape(128, 128, 200)
	            SR_ST = np.transpose(SR_ST, axes=(2, 0, 1))
	            SR_ST_all.append(SR_ST)
	            self.gene_scale.append(gene_order)  # 记录基因顺序
	
	            # ------------------- 加载spot_ST -------------------
	            spot_st_path = f"{data_root}{dataset_use}/spot_ST/{patch_id}/spot_ST_1000.npz"
	            spot_ST = sp_sparse.load_npz(os.path.join(data_root,dataset_use, 'spot_ST/extract/',sample_id, patch_id, 'spot_ST.npz')).toarray().reshape(26, 26, 200)
	            spot_ST = np.transpose(spot_ST, axes=(2, 0, 1))
	            spot_ST_all.append(spot_ST)
	
	            # ------------------- 加载WSI -------------------
	            wsi_path = f"{data_root}{dataset_use}/WSI/extract/20240611mousekidney/{patch_id}/5120_to256.npy"
	            WSI_5120 = np.load(wsi_path)
	            WSI_5120 = np.transpose(WSI_5120, axes=(2, 0, 1))
	            WSI_5120_all.append(WSI_5120)
	            wsi_320_path = os.path.join(data_root,dataset_use, "WSI", "extract", sample_id, patch_id, "320_to16.npy")
	            #print(wsi_320_path)
	            WSI_320 = np.load(wsi_320_path)
	            WSI_320 = np.transpose(WSI_320, axes=(0, 3, 1, 2))
	            WSI_320_all.append(WSI_320)
	       
	        # 转换为numpy数组
	        self.SR_ST_all = np.array(SR_ST_all).astype(np.float64)
	        #print(gene_order)
	        #print(self.SR_ST_all.shape)
	        self.SR_ST_all = self.SR_ST_all[:, gene_order, ...].astype(np.float64)
	        self.spot_ST_all = np.array(spot_ST_all).astype(np.float64)
	        self.spot_ST_all = self.spot_ST_all[:, gene_order, ...].astype(np.float64)
	        self.WSI_5120_all = np.array(WSI_5120_all)
	        self.WSI_320_all = np.array(WSI_320_all)
	
	        self.gene_scale = np.array(self.gene_scale)
	
	        # 数据标准化（保持原有逻辑）
	        for data_arr in [self.SR_ST_all, self.spot_ST_all]:
	            for ii in range(data_arr.shape[0]):
	                for jj in range(data_arr.shape[1]):
	                    if np.sum(data_arr[ii, jj]) != 0:
	                        Min, Max = data_arr[ii, jj].min(), data_arr[ii, jj].max()
	                        data_arr[ii, jj] = (data_arr[ii, jj] - Min) / (Max - Min + 1e-8)
	        #print('self.SR_ST_all',self.SR_ST_all.shape)
	        # print('self.spot_ST_all',self.spot_ST_all.shape)
	        # 加载 BERT 模型，提取基因名称特征
	        self.tokenizer = AutoTokenizer.from_pretrained("/media/cbtil/T7 Shield/NMI/bert",
	                                                         local_files_only=True, trust_remote_code=True)
	        self.model = AutoModel.from_pretrained("/media/cbtil/T7 Shield/NMI/bert",
	                                                 local_files_only=True, trust_remote_code=True)
	        self.model.eval()
	        
	        if isinstance(gene_name_order, str) and os.path.exists(gene_name_order):
	            with open(gene_name_order, "r") as f:
	                gene_names = [f"This gene’s name is called {line.strip()}." for line in f if line.strip()]
	        else:
	            gene_names = [f"This gene’s name is called {gene}." for gene in gene_name_order]
	        print("前5个基因名称句子：", gene_names[:5])
	        
	        gene_feats = []
	        with torch.no_grad():
	            for gene in gene_names:
	                inputs = self.tokenizer(gene, return_tensors="pt")
	                outputs = self.model(**inputs)
	                gene_embedding = outputs.pooler_output.squeeze(0)
	                gene_feats.append(gene_embedding)
	        self.gene_name_features = torch.stack(gene_feats, dim=0)
	        print('gene_name_features shape:', self.gene_name_features.shape)
	        
	        metadata_prompt = ("Provide spatial transcriptomics data from the VisiumHD platform for mouse species, with a healthy condition, and kidney tissue type.")
	        with torch.no_grad():
	            inputs = self.tokenizer(metadata_prompt, return_tensors="pt")
	            outputs = self.model(**inputs)
	            self.metadata_feature = outputs.pooler_output.squeeze(0)
	        print('metadata_feature shape:', self.metadata_feature.shape)
	        print(f"Test模式下，选中的patch数量：{len(self.selected_patches)}")
	    def __len__(self):
	        return len(self.selected_patches)  # 直接以筛选后的样本数为准
	
	    def __getitem__(self, index):
	        # 基因位置编码（保持原有逻辑）
	        gene_class = self.gene_scale[index]
	        Gene_index_maps = [
	            np.ones((256, 256, 1)) * gray_value_of_gene(code, self.gene_order) / 255.0
	            for code in gene_class
	        ]
	        final_Gene_index_map = np.concatenate(Gene_index_maps, axis=2).transpose(2, 0, 1)
	        
	        return (
	            self.SR_ST_all[index],
	            self.spot_ST_all[index],
	            self.WSI_5120_all[index],
	            self.WSI_320_all[index],
	            gene_class,
	            final_Gene_index_map,
	            self.gene_name_features,   # shape: [gene_num, hidden_size]
	            self.metadata_feature 
	        )

修改初始化
	
	def load_data(data_root,dataset_use,status,SR_times,gene_num,all_gene,gene_order=None,gene_name_order=None
	):
	
	    if dataset_use=='Xenium':
	        dataset= Xenium_dataset(data_root,SR_times,status,gene_num,all_gene)
	    elif dataset_use=='SGE':
	        dataset= SGE_dataset(data_root,gene_num,all_gene)
	    elif dataset_use=='BreastST':
	        dataset= BreastST_dataset(data_root,gene_num,all_gene)
	    elif 'Xenium5k_' in dataset_use:
	       dataset= Xenium5k(data_root,dataset_use,SR_times,status,gene_num,all_gene,gene_order)
	    elif 'VisiumHD_mouseembryo_sorted_data1' in dataset_use:
	       dataset= Xenium5k2(data_root,dataset_use,SR_times,status,gene_num,all_gene,gene_order,gene_name_order)
	    elif 'Visiumhd_mouse_kidney' in dataset_use:
	       dataset= Visiumhdmousekidney(data_root,dataset_use,SR_times,status,gene_num,all_gene,gene_order,gene_name_order)   
	    elif dataset_use=='Human-brain-glioblastomamultiforme':
	        dataset=Xenium_humanbrain(data_root,dataset_use,SR_times,status,gene_num,all_gene,gene_order)
	    elif 'Visiumhd_human_Tonsil' in dataset_use:
	       dataset= VisiumhdhumanTonsil(data_root,dataset_use,SR_times,status,gene_num,all_gene,gene_order,gene_name_order)
	    return dataset


## 修改meta_prompt

	 metadata_prompt = ("Provide spatial transcriptomics data from the VisiumHD platform for mouse species, with a healthy condition, and kidney tissue type.")

修改成

	metadata_prompt = ("Provide spatial transcriptomics data from the VisiumHD platform for human species, with a healthy condition, and Tonsil tissue type.")


## 新的train函数

模仿/media/cbtil/T7 Shield/NMI/code/train_VisiumHD_mouse_kidney.py

修改出/media/cbtil/T7 Shield/NMI/code/train_VisiumHD_human_Tonsil.py

## 转移代码到新服务器

改一下一些路径就行

## 监督实验完成

### visiumhd-mouse-kidney

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1746344797776.png)

### visiumhd-human-Tonsil

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1746344660974.png)