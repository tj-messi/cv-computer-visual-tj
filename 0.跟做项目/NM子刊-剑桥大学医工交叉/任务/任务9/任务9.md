# 新数据

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1746835953170.jpg)

## 模仿

模仿剑桥1号服务器：/media/cbtil/T7 Shield/NMI/code/train_cervixcancer_1.py

模仿东北大学v100服务器：/date/hanyu/TEMP/hanyu_code/NC-code3.18/guided_diffusion/image_datasets.py

## 修改结果

train类

    /media/cbtil/T7 Shield/NMI/code/train_frozenmousebrain_1.py

train类代码：

    import argparse
    import yaml
    import argparse, time, random
    from guided_diffusion import dist_util, logger
    from guided_diffusion.img import load_data
    from guided_diffusion.resample import create_named_schedule_sampler
    from guided_diffusion.script_util import (
        sr_create_model_and_diffusion,
        add_dict_to_argparser
    )
    import torch
    import os
    from guided_diffusion.train_util import TrainLoop
    import numpy as np
    from mpi4py import MPI
    comm =MPI.COMM_WORLD
    rank = comm.Get_rank()

    # 定义 GPU ID 列表，根据 rank 来选择对应的 GPU
    gpu_ids = [0]  # GPU 0 和 GPU 1
    torch.cuda.set_device(gpu_ids[rank])
    from train_part import train_fun
    def main():
        # Parse command-line arguments and set up distributed training
        args = create_argparser().parse_args()
        dist_util.setup_dist()
        args.all_gene = 1000 #change
        args.gene_num = 20 #change
        args.batch_size= 4 #change
        args.SR_times= 10
        args.dataset_use = 'Xenium5k_frozenmousebrain'
        args.epoch = 500
        args.data_root = '/media/cbtil/T7 Shield/NMI/data/'
        gene_order_path = os.path.join(args.data_root, args.dataset_use+'/gene_order.npy')
        genename_path=os.path.join(args.data_root, args.dataset_use+'/gene_names.txt')
        n=1
        log_dir = 'Xenium5k_frozenmousebrain/'
        #n=xy1,2[01] zc 34[23]  xx 56[45] 
        train_fun(args,log_dir,gene_order_path,genename_path,n)

    def create_argparser():
        parser = argparse.ArgumentParser()
        parser.add_argument("--./config/config_train.yaml", help="Path to YAML configuration file")
        args = parser.parse_args()

        # Load the configuration from the YAML file
        with open('/home/zeiler/NMI/code/config/config_train.yaml', "r") as file:
            config = yaml.safe_load(file)

        # Add the configuration values to the argument parser
        add_dict_to_argparser(parser, config)

        return parser


    if __name__ == "__main__":

        main()


image类

image类代码：

使用cb1号服务器中的cervixcancer类和humanbreast类修改

修改内容：提示词

    "Provide spatial transcriptomics data from the Xenium5k platform for mouse species, with a cancer condition, and brain tissue type."


修改内容：bert路径

    self.tokenizer = AutoTokenizer.from_pretrained("/media/cbtil/T7 Shield/NMI/bert", local_files_only=True, trust_remote_code=True)
            self.model = AutoModel.from_pretrained("/media/cbtil/T7 Shield/NMI/bert", local_files_only=True, trust_remote_code=True)


修改内容：基因数量，基于gene_name里面的行数

        self.selected_patches = []
        self.gene_order = gene_order
        self.gene_name_order = gene_name_order
        self.gene_num = 1000

修改内容：数据划分方法，直接去v100服务器里面找那个iamge_datasets.py文件里面的文件里面的直接调用，不用自己写了

    for sample_id in sample_name:
                # 以HR_ST目录为基准获取所有patch列表（假设其他数据目录结构相同）
                    base_path = f"{data_root}{dataset_use}/HR_ST/extract/{sample_id}/"
                    print('base_path',base_path)
                    sub_patches = os.listdir(base_path)
                    
                    # 第一步：收集该样本的所有有效行号
                    row_numbers = []
                    for patch_id in sub_patches:
                        parts = patch_id.split('_')
                        if len(parts) < 2:
                            continue  # 跳过非法格式
                        try:
                            b = int(parts[1])  # 提取行号
                            row_numbers.append(b)
                        except ValueError:
                            continue  # 跳过无法转换为整数的情况
                    
                    # 第二步：计算分界点（获取独特的行号并排序）
                    unique_rows = sorted(set(row_numbers))
                    total_rows = len(unique_rows)
                    # print(total_rows,total_rows)
                    # 第三步：根据总行数确定训练/测试分界点
                    if total_rows <= 5:
                        # 如果总行数≤4，最后1行用9于测试
                        train_max_row = unique_rows[-2] if total_rows > 1 else -1
                    elif total_rows <= 10:
                        # 如果总行数在5-8之间，最后2行用于测试
                        train_max_row = unique_rows[-3]
                    else:
                        # 如果行数更多，大约20%用于测试（向上取整）
                        test_count = max(int(total_rows * 0.2 + 0.5), 3)  # 至少3行测试
                        train_max_row = unique_rows[-(test_count + 1)]
                    # print(train_max_row)
                    # 第四步：遍历patch并应用新的划分逻辑
                    for patch_id in sub_patches:
                        parts = patch_id.split('_')
                        if len(parts) < 2:
                            continue  # 跳过非法格式
                        
                        try:
                            b = int(parts[1])  # 提取行号
                            
                            # 应用新的动态划分规则
                            if status == 'Train' and (train_max_row == -1 or b <= train_max_row):
                                # print('patch_id',patch_id)
                                self.selected_patches.append((sample_id, patch_id))
                            # elif status == 'Test' and (train_max_row == -1 or b > train_max_row):
                            #     self.selected_patches.append((sample_id, patch_id))
                            if status == 'Test' :
                                self.selected_patches.append((sample_id, patch_id))
                        except ValueError:
                            continue  # 跳过无法转换为整数的情况


修改内容：Unet的UNetModel类

            # co_expression = np.load('./gene_coexpre.npy')
            co_expression = np.load(root + 'Xenium5k_frozenmousebrain/gene_coexpre.npy')

            ch = input_ch = int(channel_mult[0] * model_channels)
        co_expression = np.load(root + 'Xenium5k_frozenmousebrain/gene_coexpre.npy')

## 尝试运行

![](https://cdn.jsdelivr.net/gh/tj-messi/picture/1746870702255.png)

## 四组数据集统筹

### 1号服务器：

cervical cancer ：0卡

frozen mouse brain ： 1卡


### 4号服务器：

humanbreast ：0卡

ovary ovarian cancer ：1卡

## 四组数据前100组基因结果(5/12 4:28 美中时间)

cervix cancer :  140组

    /media/cbtil/T7 Shield/NMI/code/Xenium5k_cervixcervicalcancer

frozen mouse brain : 360组

    /media/cbtil/T7 Shield/NMI/code/Xenium5k_frozenmousebrain/Xenium5k_frozenmousebrain/10X

human breast : 760组

    /home/zeiler/NMI/code/logsXenium5k_humanbreast

ovary ovarian cancer : 220组

    /home/zeiler/NMI/code/logsXenium5k_ovaryovariancancer/Xenium5k_ovaryovariancancer/10X


## 四组服务器集中

    scp -r zeiler@10.241.177.81:/home/zeiler/NMI/code/Xenium5k_humanbreast "/media/cbtil/T7 Shield/NMI/code"

    scp -r zeiler@10.241.177.81:/home/zeiler/NMI/code/Xenium5k_ovaryovariancancer "/media/cbtil/T7 Shield/NMI/code"

## 数据地址

cb服务器内：

    /media/cbtil/T7 Shield/NMI/code/Xenium5k_cervixcervicalcancer

    /media/cbtil/T7 Shield/NMI/code/Xenium5k_frozenmousebrain

    /media/cbtil/T7 Shield/NMI/code/Xenium5k_humanbreast

    /media/cbtil/T7 Shield/NMI/code/Xenium5k_ovaryovariancancer