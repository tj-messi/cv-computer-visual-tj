#前后模块结合

#改抽取的label！！！

##classes
###data_classes.txt
	
	This is the PNoCa_512 figure.
	This is the PCAT0_512 figure.
	This is the PCAT1_512 figure.

超声影像的data_class

##data
###data_class_mapping.json

	[
	  "PNoCa_512",
	  "PCAT0_512",
	  "PCAT1_512"
	]

写好三个无病，前期，晚期的map
  
##video_dataset
###dataloader.py

####def create_train_dataset (args: argparse.Namespace) -> torch.utils.data.Dataset:

里面return一个VideoDataset的类

	return VideoDataset(
	        list_path=args.train_list_path,
	        data_root=args.train_data_root or args.data_root,
	        num_spatial_views=1, num_temporal_views=1, random_sample=True,
	        auto_augment=args.auto_augment,
	        interpolation=args.interpolation,
	        mirror=args.mirror,
	        num_frames=args.num_frames,
	        sampling_rate=-1 if args.tsn_sampling else args.sampling_rate,
	        spatial_size=args.spatial_size,
	        **_parse_mean_and_std(args),
	    )

####def create_train_loader(args: argparse.Namespace, resume_step: int = 0) -> torch.utils.data.DataLoader:

里面调用create_train_dataset

	ataset = create_train_dataset(args)

这时候看到dataset.py

###dataset.py

####class VideoDataset(torch.utils.data.Dataset):

注意label的获取方法

    def __getitem__(self, idx):
        line = self.data_list[idx]
        # print(line)
        path, label = line.split(',')
        ## 拿到的label
        path = os.path.join(self.data_root, path)
        # print(path)
        label = int(label)

之后到训练train中

##training

###train.py

这是训练流程

	for i, (data, labels) in enumerate(train_loader, resume_step):
	        data, labels = data.cuda(), labels.cuda()
	        data_ed = datetime.now()
	
	        optimizer.zero_grad()
	
	        assert data.size(0) % args.batch_split == 0
	        split_size = data.size(0) // args.batch_split
	        hit1, hit5, loss_value = 0, 0, 0
	        for j in range(args.batch_split):
	            data_slice = data[split_size * j: split_size * (j + 1)]
	            labels_slice = labels[split_size * j: split_size * (j + 1)]
	
	            with torch.cuda.amp.autocast(args.fp16):
	                logits = model(data_slice)
	                loss = criterion(logits, labels_slice)
	                
	            if labels.dtype == torch.long: # no mixup, can calculate accuracy
	                hit1 += (logits.topk(1, dim=1)[1] == labels_slice.view(-1, 1)).sum().item()
	                hit5 += (logits.topk(5, dim=1)[1] == labels_slice.view(-1, 1)).sum().item()
	            loss_value += loss.item() / args.batch_split
	            
	            loss_scaler.scale(loss / args.batch_split).backward()


其中i和(data,labels)从train loader中拿出来

	 for i, (data, labels) in enumerate(train_loader, resume_step):

拿出data和labels
	
	data, labels = data.cuda(), labels.cuda()

按照论文的训练要求

	for j in range(args.batch_split):
	            data_slice = data[split_size * j: split_size * (j + 1)]
	            labels_slice = labels[split_size * j: split_size * (j + 1)]

拆开slice内容

那么我们就要在之前拿出labels的时候就用MEDSAM去更新